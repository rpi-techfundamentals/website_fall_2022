{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRlGzpOI8eO0"
   },
   "source": [
    "\n",
    "[![AnalyticsDojo](https://github.com/rpi-techfundamentals/spring2019-materials/blob/master/fig/final-logo.png?raw=1)](http://rpi.analyticsdojo.com)\n",
    "<center><h1>Titanic Classification - Keras API</h1></center>\n",
    "<center><h3><a href = 'http://introml.analyticsdojo.com'>introml.analyticsdojo.com</a></h3></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XovA71E3XFM"
   },
   "source": [
    "# Titanic Classification - Deep Learning Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pW1UhJT8ePk"
   },
   "source": [
    "As an example of how to work with both categorical and numerical data, we will perform survival predicition for the passengers of the HMS Titanic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvj3Wids8ePm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/rpi-techfundamentals/spring2019-materials/master/input/train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/rpi-techfundamentals/spring2019-materials/master/input/test.csv')\n",
    "\n",
    "print(train.columns, test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xqjk2-P8ePp"
   },
   "source": [
    "Here is a broad description of the keys and what they mean:\n",
    "\n",
    "```\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "boat            Lifeboat\n",
    "body            Body Identification Number\n",
    "home.dest       Home/Destination\n",
    "```\n",
    "\n",
    "In general, it looks like `name`, `sex`, `cabin`, `embarked`, `boat`, `body`, and `homedest` may be candidates for categorical features, while the rest appear to be numerical features. We can also look at the first couple of rows in the dataset to get a better understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqmMR9G78ePr"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54WY6zD78ePv"
   },
   "source": [
    "### Preprocessing function\n",
    "\n",
    "We want to create a preprocessing function that can address transformation of our train and test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKX26KU34Ti6"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "cat_features = ['Pclass', 'Sex', 'Embarked']\n",
    "num_features =  [ 'Age', 'SibSp', 'Parch', 'Fare'  ]\n",
    "\n",
    "\n",
    "def preprocess(df, num_features, cat_features, dv):\n",
    "    features = cat_features + num_features\n",
    "    if dv in df.columns:\n",
    "      y = df[dv]\n",
    "    else:\n",
    "      y=None \n",
    "    #Address missing variables\n",
    "    print(\"Total missing values before processing:\", df[features].isna().sum().sum() )\n",
    "  \n",
    "    imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    df[cat_features]=imp_mode.fit_transform(df[cat_features] )\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    df[num_features]=imp_mean.fit_transform(df[num_features])\n",
    "    print(\"Total missing values after processing:\", df[features].isna().sum().sum() )\n",
    "   \n",
    "    X = pd.get_dummies(df[features], columns=cat_features, drop_first=True)\n",
    "    return y,X\n",
    "\n",
    "y, X =  preprocess(train, num_features, cat_features, 'Survived')\n",
    "test_y, test_X = preprocess(test, num_features, cat_features, 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bV5s-bSMJPne"
   },
   "source": [
    "### Train Test Split\n",
    "\n",
    "Now we are ready to model. We are going to separate our Kaggle given data into a \"Train\" and a \"Validation\" set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icKFkwZQpvCs"
   },
   "outputs": [],
   "source": [
    "#Import Module\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=122,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfJues_6jaXA"
   },
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mG9S2aUvh2Cl"
   },
   "source": [
    "### Sequential Model Classification. \n",
    "\n",
    "This is our training. We do all of the preprocessing our old way and just use the dataframe.values to pass to Keras.\n",
    "\n",
    "https://keras.io/guides/sequential_model/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAUV7oYp7HZV"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import metrics\n",
    "\n",
    "\n",
    "#Create our model using sequential mode\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=9, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uiIwmm2kJ8e"
   },
   "outputs": [],
   "source": [
    "#Specify the model \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Fit the model\n",
    "model.fit(train_X.values, train_y.values, epochs=100, batch_size=20, verbose=2)\n",
    "\n",
    "_, trainperf = model.evaluate(train_X, train_y)\n",
    "_, testperf = model.evaluate(val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGoUxc7brPIg"
   },
   "outputs": [],
   "source": [
    "# Alternate Sequential syntax\n",
    "import tensorflow as tf\n",
    "altmodel = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20, input_dim=9, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "altmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "altmodel.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChXuWRtpqMhy"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Specify the model \n",
    "#Fit the model\n",
    "altmodel.fit(train_X.values, train_y.values, epochs=100, batch_size=20, verbose=2)\n",
    "\n",
    "_, altmodelTrainperf = altmodel.evaluate(train_X, train_y)\n",
    "_, altmodelValPerf = altmodel.evaluate(val_X, val_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s16HjNlF--Th"
   },
   "source": [
    "## Functional Model \n",
    "\n",
    "https://keras.io/guides/functional_api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dz7_nsvP3XEI"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(9,))\n",
    "x = tf.keras.layers.Dense(20, activation=tf.nn.relu)(inputs)\n",
    "x = tf.keras.layers.Dense(100, activation=tf.nn.relu)(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "modelalt2 = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"classifier\")\n",
    "modelalt2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WGgsasSf80U"
   },
   "source": [
    "# The Keras Model Subclassing Methods.\n",
    "\n",
    "https://keras.io/api/models/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wPaXBZOfg9U"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.dense1 = tf.keras.layers.Dense(20, input_dim=9, activation=tf.nn.relu)\n",
    "    self.dense2 = tf.keras.layers.Dense(100, activation=tf.nn.relu)\n",
    "    self.dense3 = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    x = self.dense2(x)\n",
    "    return self.dense3(x)\n",
    "\n",
    "altmodel3 = MyModel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O10sGaYHD_n0"
   },
   "outputs": [],
   "source": [
    "altmodel3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#Fit the model\n",
    "altmodel3.fit(train_X.values, train_y.values, epochs=100, batch_size=20, verbose=2)\n",
    "\n",
    "altmodel3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4onf6A9A3YCZ"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DeepLearningTitanic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}