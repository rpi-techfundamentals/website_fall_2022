{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8k48eZMpi9U"
   },
   "source": [
    "\n",
    "[![AnalyticsDojo](https://github.com/rpi-techfundamentals/spring2019-materials/blob/master/fig/final-logo.png?raw=1)](http://rpi.analyticsdojo.com)\n",
    "<center><h1>Introduction to API's with Python</h1></center>\n",
    "<center><h3><a href = 'http://introml.analyticsdojo.com'>rpi.analyticsdojo.com</a></h3></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUJnFCHgpi9b"
   },
   "source": [
    "\n",
    "This is adopted from [Mining the Social Web, 2nd Edition](http://bit.ly/16kGNyb)\n",
    "Copyright (c) 2013, Matthew A. Russell\n",
    "All rights reserved.\n",
    "\n",
    "This work is licensed under the [Simplified BSD License](https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/blob/master/LICENSE.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BbhBJEttpi9f"
   },
   "source": [
    "### Before you Begin #1\n",
    "If you are working locally or on colab, this exercise requires the twitter package and the ruamel.yaml package.   Yaml files are structured files useful for storing configuration. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ayOChWv3pi9k"
   },
   "outputs": [],
   "source": [
    " !pip install twitter ruamel.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REhWPaFqpi9y"
   },
   "outputs": [],
   "source": [
    "#see if it worked by importing the twitter package & some other things we will use.  \n",
    "from  twitter import *\n",
    "import datetime, traceback \n",
    "import json\n",
    "import time\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZceZWICCpi9_"
   },
   "source": [
    "### Before you Begin #2\n",
    "Download the sample configuration.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_lUk3c4pi-D"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/rpi-techfundamentals/spring2019-materials/master/04-viz-api-scraper/screen_names.csv && wget https://raw.githubusercontent.com/rpi-techfundamentals/spring2019-materials/master/04-viz-api-scraper/twitlab.py \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j3zwhJU30ubs"
   },
   "source": [
    "## Download Authorization file (look at Webex Teams for file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXBkHKYR0tKt"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "estmos5Mpi-K"
   },
   "source": [
    "## Step1.  Loading Authorization Data\n",
    "- Here we are going to store the authorization data in a .YAML file rather than directly in the notebook.  \n",
    "- We have also added `config.yaml` to the `.gitignore` file so we won't accidentally commit our sensitive data to the repository.\n",
    "- You should generally keep sensitive data out of all git repositories (public or private) but definitely Public. \n",
    "- If you ever accidentally commit data to a public repository you must consider it compromised.\n",
    "- A .yaml file is a common way to store configuration data, but it is not really secure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3bMB-8t5pi-O"
   },
   "outputs": [],
   "source": [
    "#This will import some required libraries.\n",
    "import sys \n",
    "import ruamel.yaml #A .yaml file \n",
    "#This is your configuration file. \n",
    "twitter_yaml='config.yaml'\n",
    "with open(twitter_yaml, 'r') as yaml_t:\n",
    "    cf_t=ruamel.yaml.round_trip_load(yaml_t, preserve_quotes=True)\n",
    "\n",
    "#You can check your config was loaded by printing, but you should not commit this.\n",
    "cf_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4oceJAex3dZh"
   },
   "source": [
    "## `cat` command to look at files\n",
    "We can use the `cat` command to look at the structure of our files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qL5lShkF3XPf"
   },
   "outputs": [],
   "source": [
    "!cat config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-on6IWMIpi-i"
   },
   "source": [
    "## Create Some Relevant Functions\n",
    "- We first will create a Twitter object we can used to authorize data.\n",
    "- Then we will get profiles.\n",
    "- Finally we will get some tweets.  \n",
    "\n",
    "**Don't worry about not understanding all the code.  Here we are pushing you us more complex functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "QCilB6v2pi-l"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def create_twitter_auth(cf_t):\n",
    "        \"\"\"Function to create a twitter object\n",
    "           Args: cf_t is configuration dictionary. \n",
    "           Returns: Twitter object.\n",
    "            \"\"\"\n",
    "        # When using twitter stream you must authorize.\n",
    "        # these tokens are necessary for user authentication\n",
    "        # create twitter API object\n",
    "\n",
    "        auth = OAuth(cf_t['access_token'], cf_t['access_token_secret'], cf_t['consumer_key'], cf_t['consumer_secret'])\n",
    "\n",
    "        try:\n",
    "            # create twitter API object\n",
    "            twitter = Twitter(auth = auth)\n",
    "        except TwitterHTTPError:\n",
    "            traceback.print_exc()\n",
    "            time.sleep(cf_t['sleep_interval'])\n",
    "        return twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU-Kd1tspi-q"
   },
   "outputs": [],
   "source": [
    "def get_profiles(twitter, names, cf_t):\n",
    "    \"\"\"Function write profiles to a file with the form *data-user-profiles.json*\n",
    "       Args: names is a list of names\n",
    "             cf_t is a list of twitter config\n",
    "       Returns: Nothing\n",
    "        \"\"\"\n",
    "    # file name for daily tracking\n",
    "    dt = datetime.datetime.now()\n",
    "    fn = cf_t['data']+'/profiles/'+dt.strftime('%Y-%m-%d-user-profiles.json')\n",
    "    with open(fn, 'w') as f:\n",
    "        for name in names:\n",
    "            print(\"Searching twitter for User profile: \", name)\n",
    "            try:\n",
    "                # create a subquery, looking up information about these users\n",
    "                # twitter API docs: https://dev.twitter.com/docs/api/1/get/users/lookup\n",
    "                profiles = twitter.users.lookup(screen_name = name)\n",
    "                sub_start_time = time.time()\n",
    "                for profile in profiles:\n",
    "                    print(\"User found. Total tweets:\", profile['statuses_count'])\n",
    "                    # now save user info\n",
    "                    f.write(json.dumps(profile))\n",
    "                    f.write(\"\\n\")\n",
    "                sub_elapsed_time = time.time() - sub_start_time;\n",
    "                if sub_elapsed_time < cf_t['sleep_interval']:\n",
    "                    time.sleep(cf_t['sleep_interval'] + 1 - sub_elapsed_time)\n",
    "            except TwitterHTTPError:\n",
    "                traceback.print_exc()\n",
    "                time.sleep(cf_t['sleep_interval'])\n",
    "                continue\n",
    "    f.close()\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOnfoSR9pi-u"
   },
   "source": [
    "## Load Twitter Handle From CSV\n",
    "- This is a .csv that has individuals we want to collect data on. \n",
    "- Go ahead and follow [AnalyticsDojo](https://twitter.com/AnalyticsDojo).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_i5FAM7pi-w"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(cf_t['file'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADSz7EZkpi-4"
   },
   "source": [
    "## Create Twitter Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bNn1Tz_opi-5"
   },
   "outputs": [],
   "source": [
    "import twitlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jLCac_eVpi-8"
   },
   "outputs": [],
   "source": [
    "#Create Twitter Object\n",
    "twitter= twitlab.create_twitter_auth(cf_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyHHXw6kpi_K"
   },
   "source": [
    "The outcoming of running the above API is to generate a twitter object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k5K_tqPSpi_L"
   },
   "source": [
    "## Step 2. Getting Help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7EZWDoSupi_M"
   },
   "outputs": [],
   "source": [
    "# We can get some help on how to use the twitter api with the following. \n",
    "help(twitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K__yJC7ypi_R"
   },
   "source": [
    "\n",
    "Go ahead and take a look at the [twitter docs](https://dev.twitter.com/rest/public).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0q3i561pi_T"
   },
   "outputs": [],
   "source": [
    "# The Yahoo! Where On Earth ID for the entire world is 1.\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/trends/place and\n",
    "# http://developer.yahoo.com/geo/geoplanet/\n",
    "\n",
    "WORLD_WOE_ID = 1\n",
    "US_WOE_ID = 23424977\n",
    "\n",
    "# Prefix ID with the underscore for query string parameterization.\n",
    "# Without the underscore, the twitter package appends the ID value\n",
    "# to the URL itself as a special case keyword argument.\n",
    "\n",
    "world_trends = twitter.trends.place(_id=WORLD_WOE_ID)\n",
    "us_trends = twitter.trends.place(_id=US_WOE_ID)\n",
    "\n",
    "print (world_trends)\n",
    "print (us_trends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMS9yeDmpi_X"
   },
   "source": [
    "## Step 3. Displaying API responses as pretty-printed JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPEUz449pi_Y"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print (json.dumps(world_trends, indent=1))\n",
    "print (json.dumps(us_trends, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OdNafaVvpi_d"
   },
   "source": [
    "Take a look at the [api docs](https://dev.twitter.com/rest/reference/get/trends/place) for the /trends/place call made above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XAUYigJ2pi_f"
   },
   "source": [
    "## Step 4. Collecting search results for a targeted hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8ZnjmSDpi_g"
   },
   "outputs": [],
   "source": [
    "# Import unquote to prevent url encoding errors in next_results\n",
    "#from urllib3 import unquote\n",
    "\n",
    "#This can be any trending topic, but let's focus on a hashtag that is relevant to the class. \n",
    "q = '#analytics' \n",
    "\n",
    "count = 100\n",
    "\n",
    "# See https://dev.twitter.com/rest/reference/get/search/tweets\n",
    "search_results = twitter.search.tweets(q=q, count=count)\n",
    "\n",
    "#This selects out \n",
    "statuses = search_results['statuses']\n",
    "\n",
    "\n",
    "# Iterate through 5 more batches of results by following the cursor\n",
    "for _ in range(5):\n",
    "    print (\"Length of statuses\", len(statuses))\n",
    "    try:\n",
    "        next_results = search_results['search_metadata']['next_results']\n",
    "        print (\"next_results\", next_results)\n",
    "    except: # No more results when next_results doesn't exist\n",
    "        break\n",
    "        \n",
    "    # Create a dictionary from next_results, which has the following form:\n",
    "    # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "    kwargs = dict([ kv.split('=') for kv in next_results[1:].split(\"&\") ])\n",
    "    print (kwargs)\n",
    "    search_results = twitter.search.tweets(**kwargs)\n",
    "    statuses += search_results['statuses']\n",
    "\n",
    "# Show one sample search result by slicing the list...\n",
    "print (json.dumps(statuses[0], indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abp_tNyTpi_k"
   },
   "outputs": [],
   "source": [
    "#Print several\n",
    "print (json.dumps(statuses[0:5], indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqzT1NZ_pi_o"
   },
   "source": [
    "## Step 5. Extracting text, screen names, and hashtags from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AMge7Gapi_p"
   },
   "outputs": [],
   "source": [
    "#We can access an individual tweet like so:\n",
    "statuses[1]['text']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MO9VaXeLpi_t"
   },
   "outputs": [],
   "source": [
    "statuses[1]['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7eplBeAMpi_x"
   },
   "outputs": [],
   "source": [
    "#notice the nested relationships.  We have to take notice of this to further access the data.\n",
    "statuses[1]['entities']['hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8GRVU9Mpi_5"
   },
   "outputs": [],
   "source": [
    "status_texts = [ status['text'] \n",
    "                 for status in statuses ]\n",
    "\n",
    "screen_names = [ user_mention['screen_name'] \n",
    "                 for status in statuses\n",
    "                     for user_mention in status['entities']['user_mentions'] ]\n",
    "\n",
    "hashtags = [ hashtag['text'] \n",
    "             for status in statuses\n",
    "                 for hashtag in status['entities']['hashtags'] ]\n",
    "\n",
    "urls = [ url['url'] \n",
    "             for status in statuses\n",
    "                 for url in status['entities']['urls'] ]\n",
    "\n",
    "\n",
    "\n",
    "# Compute a collection of all words from all tweets\n",
    "words = [ w \n",
    "          for t in status_texts \n",
    "              for w in t.split() ]\n",
    "\n",
    "# Explore the first 5 items for each...\n",
    "\n",
    "print (json.dumps(status_texts[0:5], indent=1))\n",
    "print (json.dumps(screen_names[0:5], indent=1)) \n",
    "print (json.dumps(hashtags[0:5], indent=1))\n",
    "print (json.dumps(words[0:5], indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CnGE1Erxpi_8"
   },
   "source": [
    "## Step 6. Creating a basic frequency distribution from the words in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wcm2YTAhpi_-"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for item in [words, screen_names, hashtags]:\n",
    "    c = Counter(item)\n",
    "    print (c.most_common()[:10]) # top 10, \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Thxemm3pjAA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_intro_api_twitter.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/rpi-techfundamentals/spring2019-materials/blob/master/04-viz-api-scraper/01_intro_api_twitter.ipynb",
     "timestamp": 1548900753768
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
