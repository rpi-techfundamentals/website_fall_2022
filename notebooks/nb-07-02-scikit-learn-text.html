
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>37. Bag-of-Words Using Scikit Learn &#8212; MGMT 4190/6560 Introduction to Machine Learning Applications @Rensselaer</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="38. What’s Cooking in Python" href="nb-07-03-what-cooking-python.html" />
    <link rel="prev" title="36. Natural Language Toolkit" href="nb-07-01-intro-nlp.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-32817743-6', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">MGMT 4190/6560 Introduction to Machine Learning Applications @Rensselaer</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to Introduction to Machine Learning Applications
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  NOTEBOOKS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="nb-01-01-python-overview.html">
   1. Overview of Python Features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-01-02-datastructures.html">
   3. Introduction Datastructures (Varibles, Lists, Dictionaries, and Sets)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-01-03-numpy.html">
   4. Overview of Numpy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-01-04-pandas.html">
   5. Introduction to Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-02-01-conditionals-loops.html">
   6. Conditional Statements and Loops
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-02-02-functions.html">
   7. Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-02-02a-pandas-functions.html">
   8. Introduction to Apply Function
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-02-03-null-values.html">
   9. Null Values
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-02-04-groupby.html">
   10. Groupby and Pivot Tables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-02-04-pivottable.html">
   11. More Pivottables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-02-05-kaggle-baseline.html">
   12. Kaggle Baseline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-02-EX-Exercise1.html">
   13. Exercise 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-03-01-features-dummies.html">
   14. Feature Extraction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-03-02-strings-regular-expressions.html">
   16. String Manipulation and Regular Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-03-03-visualization-python-seaborn.html">
   17. Introduction to Seaborn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-03-04-intro-python-webmining.html">
   18. Web Mining
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-03-06-matplotlib.html">
   19. MatplotLab
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-04-01-neural-networks.html">
   20. Neural Networks and the Simplist XOR Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-04-02-train-test-split.html">
   21. Train Test Splits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-04-03-intro-logistic-knn.html">
   22. Classification with Scikit-learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-04-04-knn.html">
   23. KNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-04-05-revisit-titanic0.html">
   24. Titanic Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-04-06-revisit-titanic.html">
   25. Titanic Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-04-07-titanic-features.html">
   26. Basic Text Feature Creation in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-05-01-matrix-regression-gradient-decent-python.html">
   27. Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-05-02-regression-boston-housing-python.html">
   28. Boston Housing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-05-03-ridge-lasso-python.html">
   29. Lasso Ridge Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-05-04-stats-models.html">
   30. Regression with Stats-Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-06-01-introduction-pca.html">
   31. Introduction to Principal Component Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-06-02-pca2.html">
   32. In Depth: Principal Component Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-06-03-kmeans.html">
   33. k-Means Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-06-04-covid19.html">
   34. Coronavirus Data Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-07-00-corpus-simple.html">
   35. Introduction to Text Mining in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-07-01-intro-nlp.html">
   36. Natural Language Toolkit
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   37. Bag-of-Words Using Scikit Learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-07-03-what-cooking-python.html">
   38. What’s Cooking in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-07-05-bag-popcorn-bag-words.html">
   39. Bag of Words
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-07-06-sentiment.html">
   40. Sentiment Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-07-07-sentimentB.html">
   42. Lecture-21: Introduction to Natural Language Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-07-08-fastai-imdb.html">
   44. IMDB
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-07-09-intro2.html">
   45. Introduction to Natural Language Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nb-07-10-vectorization.html">
   46. Vectorizors
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ASSIGNMENTS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../assignments/hw-1.html">
   1. Assignment-1
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://rpi.box.com/s/n53px4yfo4jpfh7qnz7qry8vecopj3np">
   Box Link
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ageron/handson-ml2">
   Hands On Machine Learning with Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://d2l.ai">
   Dive into Deep Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://www.tensorflow.org/tutorials">
   Tensorflow Tutorials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../content/capstone.html">
   <strong>
    The MS Business Analytics Capstone Course
   </strong>
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/rpi-techfundamentals/website_fall_2022/master?urlpath=tree/site/notebooks/nb-07-02-scikit-learn-text.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/rpi-techfundamentals/website_fall_2022/blob/master/site/notebooks/nb-07-02-scikit-learn-text.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/rpi-techfundamentals/website_fall_2022"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/rpi-techfundamentals/website_fall_2022/issues/new?title=Issue%20on%20page%20%2Fnotebooks/nb-07-02-scikit-learn-text.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/notebooks/nb-07-02-scikit-learn-text.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#methods-text-feature-extraction-with-bag-of-words-using-scikit-learn">
   37.1. Methods - Text Feature Extraction with Bag-of-Words Using Scikit Learn
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tf-idf-encoding">
   37.2. tf-idf Encoding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bigrams-and-n-grams">
   37.3. Bigrams and N-Grams
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#character-n-grams">
   37.4. Character n-grams
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Bag-of-Words Using Scikit Learn</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#methods-text-feature-extraction-with-bag-of-words-using-scikit-learn">
   37.1. Methods - Text Feature Extraction with Bag-of-Words Using Scikit Learn
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tf-idf-encoding">
   37.2. tf-idf Encoding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bigrams-and-n-grams">
   37.3. Bigrams and N-Grams
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#character-n-grams">
   37.4. Character n-grams
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <p><a class="reference external" href="http://rpi.analyticsdojo.com"><img alt="AnalyticsDojo" src="https://github.com/rpi-techfundamentals/spring2019-materials/blob/master/fig/final-logo.png?raw=1" /></a></p>
<center><h1>Methods - Text Feature Extraction with Bag-of-Words Using Scikit Learn</h1></center>
<center><h3><a href = 'http://rpi.analyticsdojo.com'>rpi.analyticsdojo.com</a></h3></center><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="bag-of-words-using-scikit-learn">
<h1><span class="section-number">37. </span>Bag-of-Words Using Scikit Learn<a class="headerlink" href="#bag-of-words-using-scikit-learn" title="Permalink to this headline">#</a></h1>
<section id="methods-text-feature-extraction-with-bag-of-words-using-scikit-learn">
<h2><span class="section-number">37.1. </span>Methods - Text Feature Extraction with Bag-of-Words Using Scikit Learn<a class="headerlink" href="#methods-text-feature-extraction-with-bag-of-words-using-scikit-learn" title="Permalink to this headline">#</a></h2>
<p>In many tasks, like in the classical spam detection, your input data is text.
Free text with variables length is very far from the fixed length numeric representation that we need to do machine learning with scikit-learn.
However, there is an easy and effective way to go from text data to a numeric representation using the so-called bag-of-words model, which provides a data structure that is compatible with the machine learning aglorithms in scikit-learn.</p>
<p>Let’s assume that each sample in your dataset is represented as one string, which could be just a sentence, an email, or a whole news article or book. To represent the sample, we first split the string into a list of tokens, which correspond to (somewhat normalized) words. A simple way to do this to just split by whitespace, and then lowercase the word.</p>
<p>Then, we build a vocabulary of all tokens (lowercased words) that appear in our whole dataset. This is usually a very large vocabulary.
Finally, looking at our single sample, we could show how often each word in the vocabulary appears.
We represent our string by a vector, where each entry is how often a given word in the vocabulary appears in the string.</p>
<p>As each sample will only contain very few words, most entries will be zero, leading to a very high-dimensional but sparse representation.</p>
<p>The method is called “bag-of-words,” as the order of the words is lost entirely.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Mr. Green killed Colonel Mustard in the study with the candlestick. </span><span class="se">\</span>
<span class="s2">Mr. Green is not a very nice fellow.&quot;</span><span class="p">,</span>
     <span class="s2">&quot;Professor Plum has a green plant in his study.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Miss Scarlett watered Professor Plum&#39;s green plant while he was away </span><span class="se">\</span>
<span class="s2">from his office last week.&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">vectorizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_bag_of_words</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_bag_of_words</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_bag_of_words</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_bag_of_words</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vectorizer</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">X_bag_of_words</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="tf-idf-encoding">
<h2><span class="section-number">37.2. </span>tf-idf Encoding<a class="headerlink" href="#tf-idf-encoding" title="Permalink to this headline">#</a></h2>
<p>A useful transformation that is often applied to the bag-of-word encoding is the so-called term-frequency inverse-document-frequency (tf-idf) scaling, which is a non-linear transformation of the word counts.</p>
<p>The tf-idf encoding rescales words that are common to have less weight:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="n">tfidf_vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">()</span>
<span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>tf-idfs are a way to represent documents as feature vectors. tf-idfs can be understood as a modification of the raw term frequencies (<code class="docutils literal notranslate"><span class="pre">tf</span></code>); the <code class="docutils literal notranslate"><span class="pre">tf</span></code> is the count of how often a particular word occurs in a given document. The concept behind the tf-idf is to downweight terms proportionally to the number of documents in which they occur. Here, the idea is that terms that occur in many different documents are likely unimportant or don’t contain any useful information for Natural Language Processing tasks such as document classification. If you are interested in the mathematical details and equations, see this <a class="reference external" href="http://nbviewer.jupyter.org/github/rasbt/pattern_classification/blob/master/machine_learning/scikit-learn/tfidf_scikit-learn.ipynb">external IPython Notebook</a> that walks you through the computation.</p>
</section>
<section id="bigrams-and-n-grams">
<h2><span class="section-number">37.3. </span>Bigrams and N-Grams<a class="headerlink" href="#bigrams-and-n-grams" title="Permalink to this headline">#</a></h2>
<p>In the example illustrated in the figure at the beginning of this notebook, we used the so-called 1-gram (unigram) tokenization: Each token represents a single element with regard to the splittling criterion.</p>
<p>Entirely discarding word order is not always a good idea, as composite phrases often have specific meaning, and modifiers like “not” can invert the meaning of words.</p>
<p>A simple way to include some word order are n-grams, which don’t only look at a single token, but at all pairs of neighborhing tokens. For example, in 2-gram (bigram) tokenization, we would group words together with an overlap of one word; in 3-gram (trigram) splits we would create an overlap two words, and so forth:</p>
<ul class="simple">
<li><p>original text: “this is how you get ants”</p></li>
<li><p>1-gram: “this”, “is”, “how”, “you”, “get”, “ants”</p></li>
<li><p>2-gram: “this is”, “is how”, “how you”, “you get”, “get ants”</p></li>
<li><p>3-gram: “this is how”, “is how you”, “how you get”, “you get ants”</p></li>
</ul>
<p>Which “n” we choose for “n-gram” tokenization to obtain the optimal performance in our predictive model depends on the learning algorithm, dataset, and task. Or in other words, we have consider “n” in “n-grams” as a tuning parameters, and in later notebooks, we will see how we deal with these.</p>
<p>Now, let’s create a bag of words model of bigrams using scikit-learn’s <code class="docutils literal notranslate"><span class="pre">CountVectorizer</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># look at sequences of tokens of minimum length 2 and maximum length 2</span>
<span class="n">bigram_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">bigram_vectorizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bigram_vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bigram_vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Often we want to include unigrams (single tokens) AND bigrams, wich we can do by passing the following tuple as an argument to the <code class="docutils literal notranslate"><span class="pre">ngram_range</span></code> parameter of the <code class="docutils literal notranslate"><span class="pre">CountVectorizer</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gram_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">gram_vectorizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gram_vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gram_vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="character-n-grams">
<h2><span class="section-number">37.4. </span>Character n-grams<a class="headerlink" href="#character-n-grams" title="Permalink to this headline">#</a></h2>
<p>Sometimes it is also helpful not only to look at words, but to consider single characters instead.<br />
That is particularly useful if we have very noisy data and want to identify the language, or if we want to predict something about a single word.
We can simply look at characters instead of words by setting <code class="docutils literal notranslate"><span class="pre">analyzer=&quot;char&quot;</span></code>.
Looking at single characters is usually not very informative, but looking at longer n-grams of characters could be:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">char_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">analyzer</span><span class="o">=</span><span class="s2">&quot;char&quot;</span><span class="p">)</span>
<span class="n">char_vectorizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">char_vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="nb-07-01-intro-nlp.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">36. </span>Natural Language Toolkit</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="nb-07-03-what-cooking-python.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">38. </span>What’s Cooking in Python</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Jason Kuruzovich<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>